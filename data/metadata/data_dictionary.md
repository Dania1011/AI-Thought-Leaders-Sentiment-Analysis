Data Dictionary â€” AI Thought Leaders Sentiment Analysis Platform

This document defines all dataset fields used in the projectâ€”from raw scraped fields to processed and analytical fields.

It ensures clarity, reproducibility, and correct interpretation of your data.

ğŸ§© 1. Raw Dataset Fields (Before Cleaning)

These fields come directly from scraper_nt.py when scraping Nitter.

Column Name	Type	Description
profile_name	string	Display name of the AI thought leader's profile.
username	string	The Nitter/Twitter handle (e.g., geoffreyhinton).
bio	string	Short biography from the user's profile.
location	string	Location listed on profile (may be empty).
website	string	Website URL mentioned in profile (optional).
join_date	string/date	The date the user joined the platform.
followers_count	int	Number of followers.
following_count	int	Number of accounts the user follows.
tweets_count	int	Total number of tweets by the user.
profile_image_url	string	URL of the user's profile picture.
tweet_id	string	Unique tweet identifier.
text	string	The full raw text of the tweet.
created_at	datetime	Timestamp when the tweet was posted.
lang	string	Tweet language (ISO code).
user_id_hashed	string	Hashed version of the user ID (for privacy).
comment_count	int	Number of comments on the tweet.
retweet_count	int	Number of retweets.
like_count	int	Number of likes.
is_reply	boolean	Whether the tweet is a reply.
is_retweet	boolean	Whether the tweet is a retweet.
is_quote	boolean	Whether the tweet is a quote tweet.
urls	list	List of URLs contained in the tweet (if any).
ğŸ§¼ 2. Processed Dataset Fields (After Cleaning & Combining)

These fields exist after running:

clean_and_combine.py

Column Name	Type	Description
clean_text	string	Cleaned version of tweet text: lowercased, URLs/mentions/emojis removed.
text_length	int	Character length of cleaned text.
word_count	int	Number of words in cleaned text.
has_link	boolean	True if the tweet originally contained a URL.
has_mention	boolean	True if the tweet originally contained a user mention (@user).
has_hashtag	boolean	True if the tweet contains hashtags.
processed_timestamp	datetime	The timestamp when the cleaning occurred.
source_file	string	The name of the original CSV file (e.g., karpathy.csv).

ğŸ‘‰ All raw fields (from Section 1) are also retained in the processed dataset.

ğŸ˜Š 3. Sentiment Analysis Output Fields

These fields are created after running:

sentiment_analysis.py

Column Name	Type	Description
neg_score	float	Negative sentiment intensity (0â€“1).
neu_score	float	Neutral sentiment intensity (0â€“1).
pos_score	float	Positive sentiment intensity (0â€“1).
compound_score	float	Overall sentiment score from VADER (-1 to +1).
sentiment_label	string	Final sentiment category: Positive, Negative, Neutral.
ğŸ‘¥ 4. User Sentiment Summary Fields

Generated by:

user_sentiment_summary.py


This creates a grouped summary:

Column Name	Type	Description
profile_name	string	The AI leader's display name.
Positive	int	Count of positive tweets.
Negative	int	Count of negative tweets.
Neutral	int	Count of neutral tweets.
total_tweets	int	Total tweets analyzed for that user.
positive_ratio	float	Positive tweets as ratio of total.
negative_ratio	float	Negative tweets as ratio of total.
neutral_ratio	float	Neutral tweets as ratio of total.
ğŸ—‚ï¸ 5. File-Level Output Summary
ğŸ“ Raw Data Folder (data_raw/)

Contains individual scraped CSVs:

geoffreyhinton.csv

karpathy.csv

ilyasutskever.csv

ğŸ“ Processed Data Folder (data_processed/)

cleaned_combined_tweets.csv

ğŸ“ Final Output Folder (outputs/)

sentiment_results.csv

user_sentiment_summary.csv